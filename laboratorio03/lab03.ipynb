{"cells":[{"cell_type":"markdown","metadata":{"id":"4M9cWTh0Xt1q"},"source":["Acceso al contenido de Drive"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2902,"status":"ok","timestamp":1710891598165,"user":{"displayName":"Cristhian Segura Ibarra","userId":"04450038078640446731"},"user_tz":240},"id":"LhERtghFlVGr","outputId":"0ef908ae-1d34-43e6-ea92-b273f1ca2927"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"]},{"cell_type":"markdown","metadata":{"id":"5RltkEzaYPGg"},"source":["Importando el dataset con los atributos"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44979,"status":"ok","timestamp":1710891643141,"user":{"displayName":"Cristhian Segura Ibarra","userId":"04450038078640446731"},"user_tz":240},"id":"QTuJtgqzOUgM","outputId":"2491995d-1be9-4cc7-fb1e-1d8d77152afd"},"outputs":[{"name":"stdout","output_type":"stream","text":["        3337446730  0.0064620971679687  0.00811767578125  0.85302734375  \\\n","0       7888784125            0.007748          0.006310       0.758301   \n","1       9871378905            0.005405          0.005219       0.766602   \n","2       8891869609            0.004135          0.000032       0.363281   \n","3       2006443827            0.002968          0.002892       0.757324   \n","4       7340888752            0.005707          0.004078       0.491455   \n","...            ...                 ...               ...            ...   \n","458907  5845395913            0.003967          0.005070       0.167480   \n","458908  8870843234            0.006248          0.007683       0.003338   \n","458909  8163640450            0.004993          0.003204       0.167114   \n","458910  1220825659            0.002348          0.005432       0.330078   \n","458911  2326410092            0.009079          0.009773       0.000458   \n","\n","        0.556640625  1.00390625  Unnamed: 6  0.02130126953125  0.51123046875  \\\n","0          0.686035    0.001836         NaN          0.088501       0.557129   \n","1          0.284668    1.002930         NaN          0.005821       0.854980   \n","2          0.004623    0.533691         NaN          0.002443       0.526367   \n","3          0.427734    1.001953         NaN          0.008247       0.820312   \n","4          0.684570    1.000000         NaN          0.034821       0.604980   \n","...             ...         ...         ...               ...            ...   \n","458907     0.421143    0.697266         NaN          0.059113       0.526855   \n","458908     0.006954    1.004883         NaN          0.001700       0.575195   \n","458909     0.289307    0.650879         NaN          0.007294       0.406738   \n","458910     0.003138    0.689941         NaN          0.001930       0.417969   \n","458911     0.004875    1.001953         NaN          0.007450       0.602051   \n","\n","        1.0048828125  ...  Unnamed: 179  0.50244140625  0.0023746490478515  \\\n","0           0.687988  ...           NaN       0.009544            1.002930   \n","1           0.927734  ...           NaN       0.008736            0.008751   \n","2           0.700684  ...           NaN       0.004646            0.007095   \n","3           1.001953  ...           NaN       0.000344            0.005577   \n","4           1.005859  ...           NaN       0.500488            0.000112   \n","...              ...  ...           ...            ...                 ...   \n","458907      0.852051  ...           NaN       0.005363            0.001710   \n","458908      0.885254  ...           NaN       0.008728            0.008682   \n","458909      0.632324  ...           NaN       0.002733            0.000283   \n","458910      0.846191  ...           NaN       0.007492            0.009583   \n","458911      0.715332  ...           NaN       0.006264            0.000527   \n","\n","        0.008270263671875 0.0088348388671875  0.0019130706787109  1.0078125  \\\n","0                0.002613           0.003374            0.000530   0.006649   \n","1                0.002541           0.009300            0.001654   0.000212   \n","2                0.000235           0.004581            0.004738   0.002653   \n","3                0.001367           0.005760            1.008789   1.003906   \n","4                1.009766           0.005363            1.001953   1.005859   \n","...                   ...                ...                 ...        ...   \n","458907           0.001604           0.001387            0.009468   0.000110   \n","458908           0.008438           0.008392            0.006836   0.004223   \n","458909           0.009102           0.000087            0.007229   0.000245   \n","458910           0.001172           0.005016            0.002506   0.009796   \n","458911           0.002682           0.004135            0.006561   0.003550   \n","\n","        0.0081710815429687  0.008514404296875  0.0043067932128906  \n","0                 0.006798           0.003426            0.009224  \n","1                 0.007599           0.009224            0.009636  \n","2                 0.001221           0.009529            0.007523  \n","3                 0.003401           0.001020            0.000535  \n","4                 0.004528           0.005070            0.007607  \n","...                    ...                ...                 ...  \n","458907            0.009346           0.009995            0.001259  \n","458908            0.008179           0.004337            0.003376  \n","458909            0.007935           0.007233            0.007114  \n","458910            0.001634           0.009781            0.003271  \n","458911            0.003838           0.003283            0.007168  \n","\n","[458912 rows x 189 columns]\n"]}],"source":["import pandas as pd\n","import sklearn as skl\n","\n","url = \"/content/gdrive/MyDrive/420/dataset labs/lab03/train_allx.csv\"\n","dataframe = pd.read_csv(url)\n","print(dataframe)"]},{"cell_type":"markdown","metadata":{"id":"4U8wrfNIYlXx"},"source":["Salida del método describe con un resumen del contenifo del dataframe\n","\n","count: Indica la suma de los valores no nulos de cada atributo. Los valores nulos/no presentes no suman.\n","\n","mean: Valor medio de ese atributo.\n","\n","std: Desviación estándar de los valores de ese atributo.\n","\n","min: Valor mínimo del atributo.\n","\n","25%, 50%, 75%: Se corresponde con los valores correspondientes con esos percentiles. Así, las instancias que están dentro del percentil más bajo tienen una temperatura menor de 3344.25 grados.\n","\n","max: Valor máximo para el atributo."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9986,"status":"ok","timestamp":1710891653123,"user":{"displayName":"Cristhian Segura Ibarra","userId":"04450038078640446731"},"user_tz":240},"id":"bJPaTy1nPxvS","outputId":"f2343176-fc2d-4e2d-cfd5-0c618bf47853"},"outputs":[{"name":"stdout","output_type":"stream","text":["         3337446730  0.0064620971679687  0.00811767578125  0.85302734375  \\\n","count  4.589120e+05       458912.000000      4.589120e+05  458912.000000   \n","mean   5.493556e+09            0.030989      5.030313e-03       0.314922   \n","std    2.598940e+09            0.159117      2.991349e-03       0.304572   \n","min    1.000027e+09            0.000000      5.960464e-08       0.000000   \n","25%    3.240096e+09            0.002575      2.513885e-03       0.007088   \n","50%    5.497875e+09            0.005135      5.016327e-03       0.318604   \n","75%    7.740214e+09            0.007702      7.518768e-03       0.492676   \n","max    9.999962e+09            1.009766      1.329346e-01       1.231445   \n","\n","         0.556640625    1.00390625  Unnamed: 6  0.02130126953125  \\\n","count  458912.000000  4.589120e+05  827.000000      4.589120e+05   \n","mean        0.247351  5.731712e-01    0.208288      2.058428e-01   \n","std         0.302913  3.730256e-01    0.247262      3.001298e-01   \n","min         0.000000  2.384186e-07   -0.000032      5.960464e-08   \n","25%         0.004654  2.005615e-01    0.029577      5.840302e-03   \n","50%         0.009331  5.922852e-01    0.112503      2.838135e-02   \n","75%         0.427734  1.002930e+00    0.287586      4.233398e-01   \n","max         1.009766  1.009766e+00    1.959671      2.742188e+01   \n","\n","       0.51123046875   1.0048828125  ...  Unnamed: 179  0.50244140625  \\\n","count  458912.000000  455943.000000  ...   2627.000000  446105.000000   \n","mean        0.398901       0.635249  ...      0.071998       0.061319   \n","std         0.232237       0.267547  ...      0.342564       0.184566   \n","min        -0.026611      -0.458984  ...      0.000009       0.000000   \n","25%         0.227661       0.449219  ...      0.002581       0.002779   \n","50%         0.369873       0.682617  ...      0.005344       0.005550   \n","75%         0.550781       0.862305  ...      0.007915       0.008316   \n","max         1.383789       1.009766  ...      7.000904       2.507812   \n","\n","       0.0023746490478515  0.008270263671875  0.0088348388671875  \\\n","count       458912.000000      458912.000000       458912.000000   \n","mean             0.035669           0.022050            0.013771   \n","std              0.172446           0.129467            0.093252   \n","min              0.000000           0.000000            0.000000   \n","25%              0.002579           0.002556            0.002529   \n","50%              0.005157           0.005093            0.005054   \n","75%              0.007740           0.007637            0.007572   \n","max              1.009766           1.009766            1.009766   \n","\n","       0.0019130706787109      1.0078125  0.0081710815429687  \\\n","count       458912.000000  458912.000000        4.589120e+05   \n","mean             0.087581       0.107711        5.660666e-03   \n","std              0.288582       0.303596        2.588792e-02   \n","min              0.000000       0.000000        5.960464e-08   \n","25%              0.002707       0.002783        2.504349e-03   \n","50%              0.005421       0.005569        4.997253e-03   \n","75%              0.008133       0.008347        7.499695e-03   \n","max              2.009766       1.009766        1.009766e+00   \n","\n","       0.008514404296875  0.0043067932128906  \n","count      458912.000000       458912.000000  \n","mean            0.027478            0.018162  \n","std             0.148244            0.114014  \n","min             0.000000            0.000000  \n","25%             0.002563            0.002539  \n","50%             0.005127            0.005066  \n","75%             0.007683            0.007591  \n","max             1.009766            1.009766  \n","\n","[8 rows x 187 columns]\n"]}],"source":["print(dataframe.describe())"]},{"cell_type":"markdown","metadata":{"id":"hggtsK6XY9RC"},"source":["Primero se va a seleccionar las caracteristicas numericas ya que se pudo visualizar caracteristicas con valores tipo string, posterior a ello como se puede observar hay caracteristicas que tienen el numero de valores no nulos menor a la cantidad de ejemplos, y como una alternativa se va a eliminar las caracateristicas menores a la cantidad de ejemplos : 458912  \n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7370,"status":"ok","timestamp":1710891660486,"user":{"displayName":"Cristhian Segura Ibarra","userId":"04450038078640446731"},"user_tz":240},"id":"cONwqWOuWzFg","outputId":"ffbf3576-6401-4b7e-ac24-a336c333859f"},"outputs":[{"name":"stdout","output_type":"stream","text":["        3337446730  0.0064620971679687  0.00811767578125  0.85302734375  \\\n","0       7888784125            0.007748          0.006310       0.758301   \n","1       9871378905            0.005405          0.005219       0.766602   \n","2       8891869609            0.004135          0.000032       0.363281   \n","3       2006443827            0.002968          0.002892       0.757324   \n","4       7340888752            0.005707          0.004078       0.491455   \n","...            ...                 ...               ...            ...   \n","458907  5845395913            0.003967          0.005070       0.167480   \n","458908  8870843234            0.006248          0.007683       0.003338   \n","458909  8163640450            0.004993          0.003204       0.167114   \n","458910  1220825659            0.002348          0.005432       0.330078   \n","458911  2326410092            0.009079          0.009773       0.000458   \n","\n","        0.556640625  1.00390625  0.02130126953125  0.51123046875  \\\n","0          0.686035    0.001836          0.088501       0.557129   \n","1          0.284668    1.002930          0.005821       0.854980   \n","2          0.004623    0.533691          0.002443       0.526367   \n","3          0.427734    1.001953          0.008247       0.820312   \n","4          0.684570    1.000000          0.034821       0.604980   \n","...             ...         ...               ...            ...   \n","458907     0.421143    0.697266          0.059113       0.526855   \n","458908     0.006954    1.004883          0.001700       0.575195   \n","458909     0.289307    0.650879          0.007294       0.406738   \n","458910     0.003138    0.689941          0.001930       0.417969   \n","458911     0.004875    1.001953          0.007450       0.602051   \n","\n","        0.0002276897430419  0.0001889467239379  ...  0.0041236877441406.1  \\\n","0                 0.004539            0.000088  ...              0.005260   \n","1                 0.009247            0.001914  ...              0.001832   \n","2                 0.009140            0.009819  ...              0.006512   \n","3                 0.001273            0.007137  ...              0.007729   \n","4                 0.001068            0.005692  ...              0.003723   \n","...                    ...                 ...  ...                   ...   \n","458907            0.001271            0.005650  ...              0.002235   \n","458908            0.009758            0.006317  ...              0.003298   \n","458909            0.003979            0.008354  ...              0.009682   \n","458910            0.008461            0.003508  ...              0.003258   \n","458911            0.007599            0.008469  ...              0.005127   \n","\n","        0.0288238525390625  0.0023746490478515  0.008270263671875  \\\n","0                 0.063904            1.002930           0.002613   \n","1                 0.005989            0.008751           0.002541   \n","2                -0.001622            0.007095           0.000235   \n","3                 0.011070            0.005577           0.001367   \n","4                 0.018997            0.000112           1.009766   \n","...                    ...                 ...                ...   \n","458907            0.022751            0.001710           0.001604   \n","458908            0.005508            0.008682           0.008438   \n","458909            0.013580            0.000283           0.009102   \n","458910            0.005318            0.009583           0.001172   \n","458911            0.009430            0.000527           0.002682   \n","\n","        0.0088348388671875  0.0019130706787109  1.0078125  0.0081710815429687  \\\n","0                 0.003374            0.000530   0.006649            0.006798   \n","1                 0.009300            0.001654   0.000212            0.007599   \n","2                 0.004581            0.004738   0.002653            0.001221   \n","3                 0.005760            1.008789   1.003906            0.003401   \n","4                 0.005363            1.001953   1.005859            0.004528   \n","...                    ...                 ...        ...                 ...   \n","458907            0.001387            0.009468   0.000110            0.009346   \n","458908            0.008392            0.006836   0.004223            0.008179   \n","458909            0.000087            0.007229   0.000245            0.007935   \n","458910            0.005016            0.002506   0.009796            0.001634   \n","458911            0.004135            0.006561   0.003550            0.003838   \n","\n","        0.008514404296875  0.0043067932128906  \n","0                0.003426            0.009224  \n","1                0.009224            0.009636  \n","2                0.009529            0.007523  \n","3                0.001020            0.000535  \n","4                0.005070            0.007607  \n","...                   ...                 ...  \n","458907           0.009995            0.001259  \n","458908           0.004337            0.003376  \n","458909           0.007233            0.007114  \n","458910           0.009781            0.003271  \n","458911           0.003283            0.007168  \n","\n","[458912 rows x 79 columns]\n"]}],"source":["# Seleccionar solo las columnas numéricas\n","dataframenum = dataframe.select_dtypes(include='number')\n","# Obtener el resumen del dataset\n","summary = dataframenum.describe()\n","\n","# Filtrar las columnas que tienen menos de 458912 valores no nulos\n","columns_with_few_non_nulls = summary.columns[summary.loc['count'] < 458912].tolist()\n","\n","# Eliminar las columnas con menos de 458912 valores no nulos\n","dataframex = dataframenum.drop(columns_with_few_non_nulls, axis=1)\n","\n","# Mostrar el dataframe resultante después de la eliminación\n","print(dataframex)"]},{"cell_type":"markdown","metadata":{"id":"hlShO0tbaFGa"},"source":["Salida del método describe con un resumen del contenido del dataframe resultante, y como se puede visualizar ya no se tienen valores nulos"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2861,"status":"ok","timestamp":1710891663334,"user":{"displayName":"Cristhian Segura Ibarra","userId":"04450038078640446731"},"user_tz":240},"id":"jtLWpfKEXEQO","outputId":"32865454-56f3-45d9-801a-7b8b4ce583e0"},"outputs":[{"name":"stdout","output_type":"stream","text":["         3337446730  0.0064620971679687  0.00811767578125  0.85302734375  \\\n","count  4.589120e+05       458912.000000      4.589120e+05  458912.000000   \n","mean   5.493556e+09            0.030989      5.030313e-03       0.314922   \n","std    2.598940e+09            0.159117      2.991349e-03       0.304572   \n","min    1.000027e+09            0.000000      5.960464e-08       0.000000   \n","25%    3.240096e+09            0.002575      2.513885e-03       0.007088   \n","50%    5.497875e+09            0.005135      5.016327e-03       0.318604   \n","75%    7.740214e+09            0.007702      7.518768e-03       0.492676   \n","max    9.999962e+09            1.009766      1.329346e-01       1.231445   \n","\n","         0.556640625    1.00390625  0.02130126953125  0.51123046875  \\\n","count  458912.000000  4.589120e+05      4.589120e+05  458912.000000   \n","mean        0.247351  5.731712e-01      2.058428e-01       0.398901   \n","std         0.302913  3.730256e-01      3.001298e-01       0.232237   \n","min         0.000000  2.384186e-07      5.960464e-08      -0.026611   \n","25%         0.004654  2.005615e-01      5.840302e-03       0.227661   \n","50%         0.009331  5.922852e-01      2.838135e-02       0.369873   \n","75%         0.427734  1.002930e+00      4.233398e-01       0.550781   \n","max         1.009766  1.009766e+00      2.742188e+01       1.383789   \n","\n","       0.0002276897430419  0.0001889467239379  ...  0.0041236877441406.1  \\\n","count       458912.000000       458912.000000  ...         458912.000000   \n","mean             0.059219            0.061291  ...              0.040547   \n","std              0.927442            0.866719  ...              0.267824   \n","min              0.000000            0.000000  ...              0.000000   \n","25%              0.002546            0.002554  ...              0.002571   \n","50%              0.005100            0.005104  ...              0.005135   \n","75%              0.007668            0.007660  ...              0.007702   \n","max            146.375000          159.750000  ...             22.000000   \n","\n","       0.0288238525390625  0.0023746490478515  0.008270263671875  \\\n","count       458912.000000       458912.000000      458912.000000   \n","mean             0.138047            0.035669           0.022050   \n","std              0.231574            0.172446           0.129467   \n","min             -3.572266            0.000000           0.000000   \n","25%              0.008934            0.002579           0.002556   \n","50%              0.032867            0.005157           0.005093   \n","75%              0.149780            0.007740           0.007637   \n","max              1.328125            1.009766           1.009766   \n","\n","       0.0088348388671875  0.0019130706787109      1.0078125  \\\n","count       458912.000000       458912.000000  458912.000000   \n","mean             0.013771            0.087581       0.107711   \n","std              0.093252            0.288582       0.303596   \n","min              0.000000            0.000000       0.000000   \n","25%              0.002529            0.002707       0.002783   \n","50%              0.005054            0.005421       0.005569   \n","75%              0.007572            0.008133       0.008347   \n","max              1.009766            2.009766       1.009766   \n","\n","       0.0081710815429687  0.008514404296875  0.0043067932128906  \n","count        4.589120e+05      458912.000000       458912.000000  \n","mean         5.660666e-03           0.027478            0.018162  \n","std          2.588792e-02           0.148244            0.114014  \n","min          5.960464e-08           0.000000            0.000000  \n","25%          2.504349e-03           0.002563            0.002539  \n","50%          4.997253e-03           0.005127            0.005066  \n","75%          7.499695e-03           0.007683            0.007591  \n","max          1.009766e+00           1.009766            1.009766  \n","\n","[8 rows x 79 columns]\n"]}],"source":["print(dataframex.describe())"]},{"cell_type":"markdown","metadata":{"id":"-krUv3b2tAtr"},"source":["Metodo iloc de panda para acceder a las filas y columnas\n","Ejemplo para visualizar si los datos estan correctos"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1710891663334,"user":{"displayName":"Cristhian Segura Ibarra","userId":"04450038078640446731"},"user_tz":240},"id":"D92XyazMs1qi","outputId":"f9eb8d7a-4c2e-4461-8a92-9363b5e957c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["3337446730              7.888784e+09\n","0.0064620971679687      7.747650e-03\n","0.00811767578125        6.309509e-03\n","0.85302734375           7.583008e-01\n","0.556640625             6.860352e-01\n","1.00390625              1.835823e-03\n","0.02130126953125        8.850098e-02\n","0.51123046875           5.571289e-01\n","0.0002276897430419      4.539490e-03\n","0.0001889467239379      8.809566e-05\n","0.0031909942626953      9.666443e-03\n","0.03271484375           1.361084e-01\n","0.0130996704101562      4.689941e-01\n","0.2154541015625         6.850586e-01\n","0.0091934204101562      7.701874e-03\n","0.2939453125            4.733276e-02\n","0.0242462158203125      1.307373e-01\n","0.0029716491699218      4.733887e-01\n","0.109619140625          2.000732e-01\n","0.64453125              4.086914e-01\n","0.0028133392333984      1.497269e-04\n","0.0073356628417968      3.776550e-03\n","1.0029296875            1.009766e+00\n","0.0051765441894531      4.764557e-03\n","0.0092315673828125      3.997803e-03\n","0.01361083984375        5.740356e-02\n","0.0154876708984375      1.396484e-01\n","0.06976318359375        1.618652e-01\n","0.038421630859375       1.172485e-01\n","0.0067481994628906      1.602173e-02\n","0.0179595947265625      1.553955e-01\n","0.0045204162597656      6.248474e-03\n","0.0083160400390625      8.300781e-03\n","0.007843017578125       2.548695e-04\n","0.0040779113769531      8.712769e-03\n","0.0022087097167968      4.795074e-03\n","0.0063552856445312      8.563995e-04\n","0.0048103332519531      7.190704e-03\n","0.0003230571746826      4.825592e-03\n","0.0040664672851562      6.942749e-04\n","0.0076751708984375      3.055573e-03\n","0.0041236877441406      5.237579e-03\n","0.0024375915527343      6.294250e-03\n","0.333984375             3.349609e-01\n","1                       1.000000e+00\n","0.0097198486328125      6.484985e-04\n","0.0064697265625         6.679535e-03\n","0.0034008026123046      7.125854e-03\n","0.0069694519042968      6.160736e-03\n","0.0093231201171875      5.229950e-03\n","0.0046806335449218      4.264832e-03\n","0.0078506469726562      3.332138e-03\n","0.003936767578125       1.804352e-03\n","0.02618408203125        5.987549e-02\n","0.384765625             1.152344e-01\n","0.165771484375          7.065430e-01\n","0.0010452270507812      5.585938e-01\n","0.0240936279296875      6.240234e-01\n","0.0003790855407714      2.038574e-01\n","0.0055580139160156      7.396698e-03\n","0.88134765625           6.435394e-03\n","0.001800537109375       6.889343e-03\n","0.0056953430175781      1.285553e-03\n","0.0065727233886718      1.406670e-03\n","0.0074729919433593      1.094937e-04\n","0.0020332336425781      2.260208e-03\n","0.0124893188476562      7.110596e-02\n","1.1                     1.000000e+00\n","0.0036582946777343      7.835388e-03\n","0.0041236877441406.1    5.260468e-03\n","0.0288238525390625      6.390381e-02\n","0.0023746490478515      1.002930e+00\n","0.008270263671875       2.613068e-03\n","0.0088348388671875      3.374100e-03\n","0.0019130706787109      5.302429e-04\n","1.0078125               6.649017e-03\n","0.0081710815429687      6.797791e-03\n","0.008514404296875       3.425598e-03\n","0.0043067932128906      9.223938e-03\n","Name: 0, dtype: float64\n"]}],"source":["pd.set_option('display.max_rows', None)  # Mostrar todas las filas\n","pd.set_option('display.max_columns', None)  # Mostrar todas las columnas\n","print(dataframex.iloc[0,:])"]},{"cell_type":"markdown","metadata":{"id":"AtsOFir-l8ol"},"source":["Preparación de dataset concluida"]},{"cell_type":"markdown","metadata":{"id":"2pP5hLcVls70"},"source":["#MODELO REGRESION LOGISTICA"]},{"cell_type":"markdown","metadata":{"id":"037IcFMFl6b1"},"source":["Lo que se quiere buscar con el dataset es predecir el tiempo de incumplimiento de un cliente con 79 caracteristicas y \"Y\" donde se clasifica por:\n","\n","1: Incumplimiento en 1 a 6 meses\n","\n","2: Incumplimiento en 7 a 12 meses\n","\n","3: Incumplimiento en 13 a 18 meses\n","\n","0: No es un incumplidor en 18 meses"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1710891663335,"user":{"displayName":"Cristhian Segura Ibarra","userId":"04450038078640446731"},"user_tz":240},"id":"oO8LHRF_mIpn"},"outputs":[],"source":["# utilizado para la manipulación de directorios y rutas\n","import os\n","\n","# Cálculo científico y vectorial para python\n","import numpy as np\n","\n","# Libreria para graficos\n","from matplotlib import pyplot\n","\n","# Modulo de optimizacion en scipy\n","from scipy import optimize\n","\n","# modulo para cargar archivos en formato MATLAB\n","# from scipy.io import loadmat\n","\n","# le dice a matplotlib que incruste gráficos en el cuaderno\n","%matplotlib inline"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1710891663335,"user":{"displayName":"Cristhian Segura Ibarra","userId":"04450038078640446731"},"user_tz":240},"id":"zu-zQNCUmZ3k"},"outputs":[],"source":["#Cargar los dataset procesado con pandas \n","#datax=dataframex.values\n","datax= np.loadtxt('C:/Users/kiens/OneDrive/Escritorio/1-24/SIS420/IA-SIS420 - copia/laboratorio03/train_allxPanda.csv', delimiter=',')\n","# La entrada es de 80 elemento contando con x0\n","input_layer_size  = 80\n","\n","# 4 etiquetas\n","num_labels = 4\n","#datay = np.loadtxt('/content/gdrive/MyDrive/420/dataset labs/lab03/train_y.csv')\n","datay = np.loadtxt('C:/Users/kiens/OneDrive/Escritorio/1-24/SIS420/IA-SIS420 - copia/laboratorio03/train_y.csv')\n","#Considerando el 80% para el entrenamiento\n","Xtrain = datax[:32000, :]\n","ytrain = datay[:32000]\n","# 20% para el test\n","Xtest = datax[32000:40000,:]\n","ytest = datay[32000:40000]\n","\n","\n","\n","#ytrain[ytrain == 3] = 0\n","#ytest-=1\n","#ytrain[ytrain > 0] -= 1\n","#ytest[ytest > 0] -= 1\n","\n","# print(y)\n","\n","\n","m = ytrain.size"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1710891663335,"user":{"displayName":"Cristhian Segura Ibarra","userId":"04450038078640446731"},"user_tz":240},"id":"bJMPtV3Xq-XE","outputId":"0d277246-61d5-4db3-b5e7-ef05aab9bfdb"},"outputs":[{"name":"stdout","output_type":"stream","text":["[7.88878412e+09 7.74765015e-03 6.30950928e-03 7.58300781e-01\n"," 6.86035156e-01 1.83582306e-03 8.85009766e-02 5.57128906e-01\n"," 4.53948975e-03 8.80956650e-05 9.66644287e-03 1.36108398e-01\n"," 4.68994141e-01 6.85058594e-01 7.70187378e-03 4.73327637e-02\n"," 1.30737305e-01 4.73388672e-01 2.00073242e-01 4.08691406e-01\n"," 1.49726868e-04 3.77655029e-03 1.00976562e+00 4.76455688e-03\n"," 3.99780273e-03 5.74035645e-02 1.39648438e-01 1.61865234e-01\n"," 1.17248535e-01 1.60217285e-02 1.55395508e-01 6.24847412e-03\n"," 8.30078125e-03 2.54869461e-04 8.71276855e-03 4.79507446e-03\n"," 8.56399536e-04 7.19070435e-03 4.82559204e-03 6.94274902e-04\n"," 3.05557251e-03 5.23757935e-03 6.29425049e-03 3.34960938e-01\n"," 1.00000000e+00 6.48498535e-04 6.67953491e-03 7.12585449e-03\n"," 6.16073608e-03 5.22994995e-03 4.26483154e-03 3.33213806e-03\n"," 1.80435181e-03 5.98754883e-02 1.15234375e-01 7.06542969e-01\n"," 5.58593750e-01 6.24023438e-01 2.03857422e-01 7.39669800e-03\n"," 6.43539429e-03 6.88934326e-03 1.28555298e-03 1.40666962e-03\n"," 1.09493732e-04 2.26020813e-03 7.11059570e-02 1.00000000e+00\n"," 7.83538818e-03 5.26046753e-03 6.39038086e-02 1.00292969e+00\n"," 2.61306763e-03 3.37409973e-03 5.30242920e-04 6.64901733e-03\n"," 6.79779053e-03 3.42559814e-03 9.22393799e-03]\n","[0. 0. 0. ... 0. 0. 0.]\n","(32000, 79)\n","(32000,)\n","(8000, 79)\n","(8000,)\n","[0. 0. 0. ... 0. 2. 0.]\n"]}],"source":["print(Xtrain[1,:])\n","print(ytrain)\n","print(Xtrain.shape)\n","print(ytrain.shape)\n","print(Xtest.shape)\n","print(ytest.shape)\n","print(ytest)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1710891663335,"user":{"displayName":"Cristhian Segura Ibarra","userId":"04450038078640446731"},"user_tz":240},"id":"ye_zVq6orQ0-"},"outputs":[],"source":["def  featureNormalize(X,Xt):\n","    #X_norm = X.copy()\n","    #mu = np.zeros(X.shape[1])\n","    #sigma = np.zeros(X.shape[1])\n","\n","    mu = np.mean(X, axis = 0)\n","    sigma = np.std(X, axis = 0)\n","    X_norm = (X - mu) / sigma\n","    Xt_norm = (Xt - mu) / sigma\n","\n","    return X_norm,Xt_norm, mu, sigma"]},{"cell_type":"markdown","metadata":{"id":"SIXSVgETE1HP"},"source":["Normalizar datos"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1710891663857,"user":{"displayName":"Cristhian Segura Ibarra","userId":"04450038078640446731"},"user_tz":240},"id":"ZbZSe2XrrY1u"},"outputs":[],"source":["# llama featureNormalize con los datos cargados\n","X_norm,Xt_norm, mu, sigma = featureNormalize(Xtrain,Xtest)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1710891663857,"user":{"displayName":"Cristhian Segura Ibarra","userId":"04450038078640446731"},"user_tz":240},"id":"FJQZNlAjCYqB","outputId":"e038b80a-f257-445b-8911-99f574422093"},"outputs":[{"name":"stdout","output_type":"stream","text":["(8000, 79)\n"]}],"source":["#print(X_norm)\n","#print(Xtest_norm)\n","print(Xt_norm.shape)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1710891663858,"user":{"displayName":"Cristhian Segura Ibarra","userId":"04450038078640446731"},"user_tz":240},"id":"QA9IOQUAyiUO"},"outputs":[],"source":["# Configurar la matriz adecuadamente, y agregar una columna de unos que corresponde al termino de intercepción.\n","m, n = Xtrain.shape\n","# Agraga el termino de intercepción a A\n","#X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)\n","X = X_norm\n","#x,y=Xtest.shape\n","#Xt = np.concatenate([np.ones((x, 1)), Xt_norm], axis=1)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1710891663858,"user":{"displayName":"Cristhian Segura Ibarra","userId":"04450038078640446731"},"user_tz":240},"id":"1sHBxaqUVilh","outputId":"2bdb3d8a-7edf-418e-ac77-f91d9ba2921c"},"outputs":[{"name":"stdout","output_type":"stream","text":["(32000, 79)\n","(8000, 79)\n"]}],"source":["print(X.shape)\n","print(Xt_norm.shape)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1710891663858,"user":{"displayName":"Cristhian Segura Ibarra","userId":"04450038078640446731"},"user_tz":240},"id":"Ae1GiYmPyp33"},"outputs":[],"source":["def sigmoid(z):\n","    \"\"\"\n","    Calcula la sigmoide de z.\n","    \"\"\"\n","    return 1.0 / (1.0 + np.exp(-z))"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1710891663858,"user":{"displayName":"Cristhian Segura Ibarra","userId":"04450038078640446731"},"user_tz":240},"id":"Fc1Fb1oF161r"},"outputs":[],"source":["def lrCostFunction(theta, X, y, lambda_):\n","    \"\"\"\n","    Calcula el costo de usar theta como parámetro para la regresión logística regularizada y\n","    el gradiente del costo w.r.t. a los parámetros.\n","\n","    Parametros\n","    ----------\n","    theta : array_like\n","        Parametro theta de la regresion logistica. Vector de la forma(shape) (n, ). n es el numero de caracteristicas\n","        incluida la intercepcion\n","\n","    X : array_like\n","        Dataset con la forma(shape) (m x n). m es el numero de ejemplos, y n es el numero de\n","        caracteristicas (incluida la intercepcion).\n","\n","    y : array_like\n","        El conjunto de etiquetas. Un vector con la forma (shape) (m, ). m es el numero de ejemplos\n","\n","    lambda_ : float\n","        Parametro de regularización.\n","\n","    Devuelve\n","    -------\n","    J : float\n","        El valor calculado para la funcion de costo regularizada.\n","\n","    grad : array_like\n","        Un vector de la forma (shape) (n, ) que es el gradiente de la\n","        función de costo con respecto a theta, en los valores actuales de theta..\n","    \"\"\"\n","#     alpha = 0.003\n","#     theta = theta.copy()\n","    # Inicializa algunos valores utiles\n","    m = y.size\n","\n","    # convierte las etiquetas a valores enteros si son boleanos\n","    if y.dtype == bool:\n","        y = y.astype(int)\n","\n","    J = 0\n","    grad = np.zeros(theta.shape)\n","\n","    h = sigmoid(X.dot(theta.T))\n","\n","    temp = theta\n","    temp[0] = 0\n","\n","#     J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))\n","    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","\n","    grad = (1 / m) * (h - y).dot(X)\n","#     theta = theta - (alpha / m) * (h - y).dot(X)\n","    grad = grad + (lambda_ / m) * temp\n","\n","    return J, grad\n","#    return J, theta"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1710891663859,"user":{"displayName":"Cristhian Segura Ibarra","userId":"04450038078640446731"},"user_tz":240},"id":"j7PH8CZJ2AUv"},"outputs":[],"source":["def oneVsAll(X, y, num_labels, lambda_):\n","    \"\"\"\n","    Trains num_labels logistic regression classifiers and returns\n","    each of these classifiers in a matrix all_theta, where the i-th\n","    row of all_theta corresponds to the classifier for label i.\n","\n","    Parameters\n","    ----------\n","    X : array_like\n","        The input dataset of shape (m x n). m is the number of\n","        data points, and n is the number of features. Note that we\n","        do not assume that the intercept term (or bias) is in X, however\n","        we provide the code below to add the bias term to X.\n","\n","    y : array_like\n","        The data labels. A vector of shape (m, ).\n","\n","    num_labels : int\n","        Number of possible labels.\n","\n","    lambda_ : float\n","        The logistic regularization parameter.\n","\n","    Returns\n","    -------\n","    all_theta : array_like\n","        The trained parameters for logistic regression for each class.\n","        This is a matrix of shape (K x n+1) where K is number of classes\n","        (ie. `numlabels`) and n is number of features without the bias.\n","    \"\"\"\n","    # algunas variables utiles\n","    m, n = X.shape\n","\n","    all_theta = np.zeros((num_labels, n + 1))\n","\n","    # Agrega unos a la matriz X\n","    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n","\n","    for c in np.arange(num_labels):\n","        initial_theta = np.zeros(n + 1)\n","        options = {'maxiter': 50}\n","        res = optimize.minimize(lrCostFunction,\n","                                initial_theta,\n","                                (X, (y == c), lambda_),\n","                                jac=True,\n","                                method='CG',\n","                                options=options)\n","\n","        all_theta[c] = res.x\n","\n","    return all_theta"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2555,"status":"ok","timestamp":1710891666396,"user":{"displayName":"Cristhian Segura Ibarra","userId":"04450038078640446731"},"user_tz":240},"id":"WkwQRP4I2EIQ","outputId":"c607f58b-3be0-45ef-fb59-e7f71f07633b"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n","C:\\Users\\kiens\\AppData\\Local\\Temp\\ipykernel_6320\\3271430271.py:49: RuntimeWarning: divide by zero encountered in log\n","  J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n"]},{"name":"stdout","output_type":"stream","text":["(4, 80)\n"]}],"source":["lambda_ =0.01\n","all_theta = oneVsAll(X, ytrain, num_labels, lambda_)\n","print(all_theta.shape)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1710891666396,"user":{"displayName":"Cristhian Segura Ibarra","userId":"04450038078640446731"},"user_tz":240},"id":"GwCp1rvz2ZIq","outputId":"8f629c0c-8d67-402d-972a-7cf31edcc2c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[ 2.17306871e+00  2.10718669e-02 -9.37613783e-03 -3.24179454e-04\n","   1.59898764e-01  1.87837928e-02  4.11582033e-01 -3.95437921e-01\n","   4.52316600e-01 -1.86795842e-02 -8.56255261e-03 -3.77290037e-02\n","  -3.45303198e-02 -3.79893371e-01 -3.93752350e-01 -2.92263894e-01\n","   2.84277709e-01 -7.91418264e-01  1.49768378e-01 -1.12448940e-01\n","   7.77549552e-02 -2.76910655e-01 -2.27635144e-01  1.33979330e-01\n","   7.41899963e-02  4.03434826e-02  4.52178772e-01  6.05912754e-01\n","   1.62413412e-01 -4.76337739e-02 -3.11498804e-02 -2.58970688e-01\n","  -1.43686388e-02  2.71468839e-02 -4.53613903e-02 -7.10128443e-01\n","   1.10163462e-02 -2.47172717e-02  2.60410740e-02 -1.19646843e-02\n","   1.08112093e-02 -1.51681360e-02 -1.20961660e-01  1.28980292e-02\n","   4.55387475e-01  5.29343924e-02  4.86516581e-02 -4.50012625e-03\n","  -3.98660743e-02  3.57293646e-03 -1.37045983e-02 -2.65155519e-02\n","  -2.19293588e-01  1.69524892e-01 -3.06793110e-01 -1.75147179e-01\n","  -1.00078990e-01 -5.87906928e-01  3.28249003e-01 -3.67438004e-01\n","  -2.58145998e-02  8.65035101e-02  4.55426218e-02 -5.41167855e-02\n","  -6.25688792e-02  1.23679291e-01 -8.08384186e-02 -3.72374319e-01\n","   2.13760599e-03  4.80371289e-02 -1.12433194e-01 -3.28383492e-01\n","   4.01394722e-02  1.09048400e-01 -3.93958406e-02 -1.02289562e-01\n","   2.17094695e-01  2.60814688e-02 -4.91458174e-02 -6.42088047e-02]\n"," [-4.08080054e+00 -1.69425942e-02  1.73964962e-02 -3.01563837e-02\n","  -2.58004107e-01  1.82129301e-01 -5.74749257e-01  5.65874231e-02\n","  -2.72559804e-01 -7.79964874e-03  2.88228659e-02  3.77689388e-02\n","   1.71610450e-01  1.18385195e-01  7.67538946e-01  1.83818606e-01\n","  -8.93809608e-02  2.22681478e-01 -3.36696900e-01  5.09372920e-02\n","  -9.27033527e-02  1.56404032e-01  1.01010368e-01 -3.12918450e-02\n","  -5.65567100e-02  3.38304756e-03 -2.21997242e-01 -2.30535187e-02\n","  -1.72547373e-01  2.11381985e-02  5.10996381e-03 -8.57942692e-02\n","   2.17735103e-02 -5.99708537e-03  2.76409873e-02  4.26886009e-02\n","  -5.65665131e-02 -4.79385637e-02  1.88142356e-02  3.10906180e-02\n","   1.07773340e-02  9.06257063e-03  8.91992116e-02  1.02114918e-02\n","  -3.12989183e-01 -7.17543962e-02  7.57347656e-03  4.31452839e-03\n","   2.45171219e-03 -1.03083553e-03  1.11401142e-02 -1.77286463e-02\n","   1.61612152e-01  7.17008417e-03  9.34157223e-02  2.67363648e-01\n","   3.65684740e-02  4.86463115e-01 -6.95906399e-02  1.39503911e-01\n","   2.28909525e-02 -6.86948489e-02 -7.25341571e-05  5.23469769e-02\n","  -2.08392887e-02 -1.44967748e-01  8.74777485e-02 -1.29297837e-02\n","   1.97544764e-02 -2.58292507e-02  2.75186652e-02  9.46068002e-02\n","   5.10594618e-02 -1.93535057e-01 -1.28664778e-02  1.42740867e-01\n","  -2.76625243e-01 -6.15658799e-03 -8.41242469e-03 -1.96961563e-02]\n"," [-3.41391172e+00 -1.75311352e-02  9.05791773e-03  5.79401909e-03\n","   3.89902603e-02 -2.69335310e-02 -6.37580606e-01  2.65232639e-01\n","  -3.06817320e-01  1.44394045e-02 -1.93696551e-02  2.31224664e-02\n","  -1.23001966e-01  9.27429972e-02 -3.19467163e-01 -5.46381101e-03\n","  -1.65683525e-01  3.26287719e-01 -2.92283377e-02  8.10787559e-02\n","  -2.07107094e-02  1.27651993e-01  1.20616253e-01 -1.08526356e-01\n","  -9.33076498e-02 -9.88649483e-03 -1.18556639e-01 -2.06002552e-01\n","  -2.30873447e-01 -1.24189631e-01  2.20736686e-02  2.05015803e-01\n","  -1.42304922e-02 -4.05255973e-02  3.79066409e-02 -1.34542660e-01\n","   1.41657183e-02  5.73221671e-02  1.45985949e-02 -1.03530543e-02\n","  -3.75375624e-02  2.31117679e-02 -2.91106770e-02 -2.98774683e-03\n","  -3.91804391e-01  4.54127606e-02 -3.03117814e-02 -4.67184120e-02\n","  -1.71669240e-02 -2.71449766e-02  1.30322183e-02  4.10837342e-02\n","   1.75213602e-01 -5.36434949e-02  1.57472990e-01  2.02163275e-01\n","   8.40445219e-02  3.53924756e-01 -1.64879795e-01  1.63307365e-01\n","  -2.66580662e-02 -1.73180548e-02 -3.60938577e-02  2.24006382e-02\n","   3.39516858e-02  8.66903461e-03 -8.66390510e-03  1.32473942e-01\n","  -7.04680300e-03  2.22751258e-02  3.70990854e-02  4.18874820e-03\n","  -6.74420723e-02 -2.23284355e-02  5.67688667e-02 -5.32273534e-02\n","  -3.26517613e-01 -4.50211462e-02 -1.17667394e-02  5.12421434e-02]\n"," [-3.47234229e+00  7.38343891e-03  5.01810057e-03  2.58734200e-02\n","  -1.87290392e-01  3.66738584e-02 -6.99468905e-01  7.18881625e-02\n","  -3.19000354e-01 -1.58627499e-02 -5.06919152e-03  7.43838339e-03\n","  -5.92397909e-02  1.57874595e-01 -2.48839700e-01 -9.04029063e-02\n","  -8.27148901e-02  4.21268188e-01  2.50683727e-03 -2.86932419e-02\n","  -3.91625489e-02  5.50412276e-02  2.00104111e-01 -3.12433486e-02\n","   1.26721840e-03 -5.17645747e-02 -1.72815555e-01 -3.43845285e-01\n","  -1.83812170e-01  4.79460552e-02  2.70998788e-02  2.50006967e-01\n","  -2.20586487e-01 -1.94741599e-02  3.15839635e-02  2.12409174e-01\n","   7.81332378e-02 -1.09784570e-01 -7.14057665e-02 -2.68268759e-02\n","  -2.29579273e-02 -1.53800721e-02 -1.18416840e-01 -1.23868075e-02\n","  -3.46007155e-01  5.61164013e-02 -2.91326682e-02  1.59872578e-03\n","  -4.80469904e-02  1.17367197e-02 -3.95651939e-02 -8.17403053e-03\n","   9.62816999e-02 -9.59920193e-02  1.53693669e-01  9.27623924e-02\n","   3.10723829e-02  2.67975733e-01 -1.81282453e-01  1.18261997e-01\n","   3.02504359e-02 -5.90054906e-02 -4.43199968e-02  1.85467976e-02\n","   3.35620393e-02 -2.67125656e-01  6.37914626e-02 -4.19639930e-02\n","  -3.35427978e-03 -8.12864362e-02 -3.52984053e-03  1.26421161e-01\n","  -3.46278155e-02 -1.13175454e-01  1.63780608e-02  7.55268715e-02\n","  -3.54438979e-01  1.87368981e-03 -2.71824460e-02  9.47884901e-03]]\n"]}],"source":["print(all_theta)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1710891666396,"user":{"displayName":"Cristhian Segura Ibarra","userId":"04450038078640446731"},"user_tz":240},"id":"7rMTFscE3rzl"},"outputs":[],"source":["def predictOneVsAll(all_theta, X):\n","    \"\"\"\n","    Devuelve un vector de predicciones para cada ejemplo en la matriz X.\n","    Tenga en cuenta que X contiene los ejemplos en filas.\n","    all_theta es una matriz donde la i-ésima fila es un vector theta de regresión logística entrenada para la i-ésima clase.\n","    Debe establecer p en un vector de valores de 0..K-1 (por ejemplo, p = [0, 2, 0, 1]\n","    predice clases 0, 2, 0, 1 para 4 ejemplos).\n","\n","    Parametros\n","    ----------\n","    all_theta : array_like\n","        The trained parameters for logistic regression for each class.\n","        This is a matrix of shape (K x n+1) where K is number of classes\n","        and n is number of features without the bias.\n","\n","    X : array_like\n","        Data points to predict their labels. This is a matrix of shape\n","        (m x n) where m is number of data points to predict, and n is number\n","        of features without the bias term. Note we add the bias term for X in\n","        this function.\n","\n","    Devuelve\n","    -------\n","    p : array_like\n","        The predictions for each data point in X. This is a vector of shape (m, ).\n","    \"\"\"\n","\n","    m = X.shape[0];\n","    num_labels = all_theta.shape[0]\n","\n","    p = np.zeros(m)\n","\n","    # Add ones to the X data matrix\n","    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n","    #p = np.argmax(sigmoid(X.dot(all_theta.T)), axis = 1)\n","    p = np.argmax(sigmoid(X.dot(all_theta.T)), axis=1)\n","    #print(X.shape)\n","    return p"]},{"cell_type":"markdown","metadata":{"id":"5J7TrFvKE-Ge"},"source":["Prediccion trabajado con Xtest que es el 20% y con su precision comprobado con ytest."]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1710891666396,"user":{"displayName":"Cristhian Segura Ibarra","userId":"04450038078640446731"},"user_tz":240},"id":"u74rAELvba67","outputId":"94f2b407-0cb2-4414-c4af-a3d87aa394b8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Precision del conjuto de entrenamiento: 81.15%\n","[0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 1 0 0 2 2 3 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0\n"," 0 0 0 2 2 0 2 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 2 0 0 0 0 0 0 0 0 0 1 2 0 0 3 2 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0\n"," 2 2 0 1 0 2 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 2 2 0 0 2 1 3 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 2 3 0 0 0 0 0 0 0 0 2 0 2 0\n"," 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 2\n"," 0 2 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 2 2 0 2 0 2\n"," 3 0 2 2 0 2 1 0 2 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 2 0 0 0 0 2 0 2 0 2 0 0 0 0 1 0 0 0 2 2 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 2 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 2 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 2 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 2 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 2 0 0 2 0 0 0\n"," 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0\n"," 0 0 0 2 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 2\n"," 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n"," 0 0 0 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0\n"," 0 2 0 0 0 0 0 1 1 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 3\n"," 0 0 0 0 0 1 0 0 0 2 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 2 2 0 1 1 0 2 2 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 0 2 0 0\n"," 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 1 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 2 0 2 0\n"," 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 0\n"," 2 0 0 2 0 0 0 0 0 0 0 0 2 0 1 2 0 0 0 2 2 0 0 0 0 1 0 3 0 2 0 0 1 0 0 0 2\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 2 0 0 0 2 0 0 0 0 0 0 0 0 0 1\n"," 1 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0\n"," 0 0 0 0 3 3 0 0 0 2 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 2 0 3 1 2 3 0 3 0 0 0 0 0 0 0 0 0 1 0 0 0\n"," 0 0 2 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 2 3 0 0 2 0 2 0 1 2 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0\n"," 1 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 0 0 0 1 0 0 0 0 0 3 2\n"," 0 2 0 2 2 0 2 2 1 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 3 0 0 2 0 0 0 1 0 0\n"," 0 0 0 0 0 1 0 0 3 0 1 1 0 1 0 0 2 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 2 2 0 0 0 0 0 0 0 3 2 2 0 0 0 3 3 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0\n"," 0 1 0 0 0 0 0 0 0 2 0 0 1 0 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 1 2 2 0 2 2 0 0 1 0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 2 0 0 0 2 0\n"," 0 3 0 1 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 1 0 0 0\n"," 0 0 0 0 0 1 0 1 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n"," 0 0 1 3 3 0 1 0 0 2 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0\n"," 0 0 1 0 0 0 0 0 0 1 0 0 0 2 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 2 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 2 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 2 0 0 0 1 2 0 1 1 2 3 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 2 0 0 0 2 0 0 0 0 3 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 2 0\n"," 0 0 0 2 0 2 1 0 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 1\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 2 0 2 2 0 1 2 0 2 0 1 0 0 2 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 2 0 0 3 2 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 1 2 0 1 0 1 0 0 0 0 0 1 2 0 3 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 2 2 0 0 1 0 0 0 0 2 0 0 0 0 3 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 2 2 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 0 2 2 0 0 3 2 2 0 0 3 0 2 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 3 0 0 0\n"," 2 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 1 1 0 0 0 2 0 2 1 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 2 0 0 0 0 0 0 0 2 0 2 0 0 0 0 0 0 0\n"," 0 2 0 0 0 0 0 0 1 2 0 0 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 2 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 1 0 1 0 0 0 0 2 0 2 2 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0\n"," 0 0 2 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 2 0 2 0 0 2 0 2 0 0 1 0 2 0 0 0\n"," 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 2 1 0 0 0 0 0 0 0\n"," 0 2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 2 0 0 0 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0\n"," 0 0 1 0 2 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 2\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 1 0 2 2 0 1 3 0 3 1 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 2 0 2 0 0 2 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 1 0 0 0\n"," 1 1 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0 0 2 0 2 1 2 2 0 2 0 0 0 0 0 0 1 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 1 0 0 2 2 0 2 0 0 1 0 2 0 0 0 0 2 2 0 0 0 1 0 0 0 0 2 2 1 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 1 0 0 0 0 0 2 0 0 0\n"," 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 2 2 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n"," 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n"," 0 0 2 0 1 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 2 0 0 3 2 2 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n"," 0 0 0 2 0 2 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 2 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 1 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 1 3\n"," 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 2 2\n"," 2 3 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 3 0 0 2 0 2 0 0 0 0 2 0 2 2 2 0 0 3 0 0 0 1 0 0 0 0 0\n"," 0 0 1 3 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 2 2 0 0 0 0 1 0 0 0 0\n"," 0 0 0 0 1 2 1 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 2 0 0 0 2 0 2 0 0 0 2 0 0 0 0 2 0 1 2 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 2 0 0 2 0 2 0 0 0\n"," 0 2 0 2 0 2 0 0 1 2 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n"," 0 0 0 0 0 0 0 1 0 0 2 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n"," 2 2 2 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 1 0 0 0 0 2 0 0 0 1 0 0 2 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 2 0 2 0 0 2 2 0 0 0 0 2 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 2 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 2 1 0 3 0 0 0 0 0 0 0\n"," 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 2 0\n"," 0 0 0 0 0 0 0 0 0 2 0 0 2 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 2 0 0 0 0 0 0 2 0 0 3 0 0 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 2 0 2 2 0 0 2 2 3 0 2 2 0 0 2 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 1 0 0 0 0\n"," 0 0 2 0 2 2 3 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 2 0 0 0 2 0 0 0 0 1 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0 1 2 0 0\n"," 2 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 1 0 0 0 0 0\n"," 1 0 1 1 0 1 0 0 2 0 0 0 1 0 0 0 2 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n"," 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 2 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 2\n"," 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 3 0 0 0 2 0 0 0 0 0 0 3 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 2 0 0 1 2 0 0\n"," 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 2 0 1 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 2\n"," 0 1 0 0 0 2 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 2 0\n"," 0 0 0 0 0 0 0 0 0 0 0 1 0 1 2 0 2 0 2 0 0 0 0 0 0 2 0 0 3 0 0 0 0 0 0 0 0\n"," 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0\n"," 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 2 2\n"," 0 2 2 2 2 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0\n"," 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 1 2 0 0 0 0\n"," 0 0 0 0 0 1 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 2 2 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 2 0 2 0 0 0 2 0 0 2 0 3 0\n"," 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 2 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 2 0 0 0\n"," 0 0 3 0 0 3 0 0 0 0 0 0 0 0 2 0 0 0 0 0 3 0 0 0 0 0 0 0 2 0 0 0 0 2 0 0 2\n"," 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2\n"," 2 0 3 3 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 2 0 0 0 1 0 2 3 0 1 0 0 0\n"," 1 2 0 2 0 2 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n"," 0 2 0 0 0 0 2 0 0 0 0 1 1 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 1 0 2 0 0 1 0 0 0 0 0 0 0 1 0 0 0 2 0 0 1 0 0 0 3 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 2 0 0 1 0 0 0 0 0 0 0 0 0\n"," 0 2 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 2 0 0 0 2 2 2 0 0 2 0 1 0 0 0 1 0 0 0\n"," 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 1 2 0\n"," 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 2 0 0 3 2 2 0 2 2 2 0 0 0 0 2 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n"," 0 1 0 0 0 0 0 0 2 2 1 0 0 2 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 2 3 0 0 0 0 2 0 0 0 2 2 2 2 2 2 0 0 3\n"," 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 2 0 2 1 2 0\n"," 0 2 0 0 2 0 0 2 0 2 2 0 2 0 0 1 0 0 0 0 2 0 0 1 0 0 0 2 2 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 2 2 0 0 0 0 2 0 2 1 0 0 0 0 0 2 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 2 0 1 0 1 2 0 2 0 3 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 2\n"," 0 0 0 0 1 0 0 2 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 2 0 0 0 0 0 0 0 0 0 0 1 0 2 0 1 0 2 0 0 0\n"," 2 2 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 1 0 0 0 0 0\n"," 0 2 2 0 3 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3\n"," 1 0 2 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 2\n"," 1 0 0 0 0 0 0 0 0 0 0 0 2 0 1 0 0 0 1 2 2 0 2 0 0 1 2 3 2 2 0 0 0 0 0 0 0\n"," 0 0 1 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n"," 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n"," 0 0 0 0 0 0 2 0 0 0 1 2 0 2 2 2 0 0 0 0 0 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 1 0 0 2 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 1 3 0 0 0 1 2 1 2 1\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 2 0 0 0 0 0 1 2 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 3 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 2 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 0 0 0 2 0 0 2 0 0 1 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0\n"," 0 0 2 2 0 1 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 2 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 1 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 2 0 0 0 0 1 0 0 0 0\n"," 0 0 0 2 0 2 0 0 0 0 0 0 2 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 1 0 0 2 0 0 0 0 0 0 2 2 2 0 0 0 2 0 0 0 0 3 2 0 1 0 2 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 2 0 0 1 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 1 0 2 0 0 0 2 0 0 0 0 0 0 0 3 0\n"," 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 2 0 0 0 0 0 0 0 0 2 0 1 0 0 0\n"," 0 2 0 2 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n"," 0 0 0 2 0 0 0 0 0 0 0 2 0 0 1 0 0 0 0 1 0 3 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 2 0 0 1 2 0 0 2 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 2 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 0 0 1 1\n"," 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 2 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0 1 0 0 0 0 1 2 0 0 0 1 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 2 0 0 0 2 3 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 3 2 0 0 0 0 3 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 2 0 0 0 2 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0 2 2 0 3 1 0 0 0 0 0 3 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0\n"," 1 0 0 0 2 2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 2 0 0 0 0 0 0 0\n"," 2 0 0 0 2 0 2 0 2 2 2 2 2 2 3 1 0 2 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 2 0 0 2 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n"," 1 0 0 2 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 2 1 1 1 1 0 0 0 0 0\n"," 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 0 3 1 0 0 0 0 1 2 3\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 2 0 0 0 0 0 1 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 1 0 3 2 0 0 1 0 0 2 0 0 2 0 0 3 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 1 2 2 0 0 0 0 1 0 2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0\n"," 0 2 0 0 1 0 0 0 0 0 0 0 0 0 2 0 2 2 0 3 0 3 0 2 0 0 0 0 0 0 0 0 0 0 1 2 1\n"," 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 1 0 0 0 0 0 0 0 2 0 1 0 0 2 0 0 2\n"," 0 0 2 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 2 0 0 0 0 2 0 2 0 0 0 0\n"," 0 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 2\n"," 0 0 0 0 2 2 0 1 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 2 0 3 0\n"," 1 0 0 1 2 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2\n"," 1 0 0 0 0 0 2 0 0 0 0 2 0 0 1 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 2 0 0 0\n"," 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 2 0 0 0 2 0 0 0 1 0\n"," 2 0 0 0 0 1 0 0 2 0 0 0 0 0 0 0 0 0 0 0 2 1 1 0 0 1 2 0 3 2 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 1 0 0 0 0 2 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 2 0 1 1 0 0 2 2 0 0 0 1 1 0 2 2 2\n"," 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0\n"," 0 0 0 0 0 0 0 0 0 2 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 2 0 0 1 0 2 0 0 0 0 2 0\n"," 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 0 0 2 2\n"," 1 0 0 0 0 0 0 0 2 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0\n"," 0 0 0 0 0 0 0 2 0 2 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 2 0 0 0 0 1 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 2 2 0 0\n"," 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 1 0 0 1 0 0 2\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 1 0 1 1 0 2 0 0 0\n"," 2 2 2 2 0 0 2 0]\n","[0. 0. 0. 0. 0. 1. 2. 3. 0. 0. 0. 3. 2. 0. 0. 1. 2. 1. 3. 2. 0. 0. 3. 0.\n"," 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3.\n"," 0. 0. 0. 0. 0. 2. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 3. 0. 3. 0. 0. 0. 0.\n"," 3. 0. 0. 3. 3. 3. 3. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 3. 2. 0. 3. 0. 0. 3. 0. 0. 2. 0. 0. 2. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 1. 2. 0. 0. 0. 3. 0. 3. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 1. 0. 0. 2. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 3. 0. 2. 0. 1. 2. 0. 3. 1. 0. 0. 0.\n"," 3. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 3. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3.\n"," 2. 0. 0. 0. 2. 2. 2. 3. 2. 2. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 3. 3. 0. 0. 3. 2. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 1. 0. 2. 0. 0. 0. 0. 0. 3. 0. 2. 0. 0. 3. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 2. 0. 0. 0. 2. 0. 0. 0. 3. 2. 0. 0. 0. 0. 0. 2. 0. 0. 2. 2. 3. 2.\n"," 1. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 1. 0. 0.\n"," 0. 0. 0. 0. 2. 2. 0. 3. 0. 0. 1. 0. 3. 2. 2. 3. 1. 3. 2. 0. 0. 0. 3. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 2.\n"," 3. 2. 0. 0. 2. 0. 3. 0. 3. 0. 0. 3. 1. 1. 0. 0. 3. 2. 0. 0. 2. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 2. 0. 1. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 2. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n"," 1. 0. 1. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 3. 3. 0.\n"," 0. 0. 0. 2. 0. 1. 2. 3. 0. 0. 0. 0. 0. 3. 0. 1. 2. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 0. 0. 3. 3. 0. 0. 0. 0. 0. 0. 2. 3. 0. 0.\n"," 0. 0. 0. 0. 3. 0. 0. 3. 0. 3. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 3. 2. 0. 0.\n"," 0. 0. 2. 0. 0. 0. 0. 0. 2. 0. 0. 0. 1. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 2.\n"," 0. 2. 2. 3. 0. 0. 2. 0. 2. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 3. 0. 0. 0. 3.\n"," 0. 0. 2. 0. 0. 1. 3. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 1. 1. 2. 0. 0. 0. 3. 0. 0. 0. 3. 0. 0. 0.\n"," 2. 0. 0. 1. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 3. 0. 0. 3.\n"," 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 3. 1. 0. 0. 0. 3. 1. 3. 0. 3. 2. 3. 0. 3.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0.\n"," 0. 0. 0. 3. 0. 0. 0. 2. 2. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 1. 3. 0. 0. 0.\n"," 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 3. 0. 0. 0. 0. 0. 0. 0. 0. 3. 2. 0. 2. 2. 0. 3. 2. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 2. 1. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3. 2. 0. 0. 0. 0.\n"," 0. 2. 1. 3. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 1. 2. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 3. 0. 1. 0. 0. 1. 0. 2. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 2. 0. 2. 3. 3. 0. 0. 3. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0.\n"," 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 1. 2. 3. 0. 1. 2.\n"," 2. 2. 2. 0. 0. 1. 0. 2. 0. 2. 0. 0. 1. 0. 2. 2. 3. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 1. 2. 1. 0. 0. 0. 0. 0. 0. 1. 0. 2. 3. 0.\n"," 0. 2. 0. 0. 0. 1. 1. 0. 1. 1. 3. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 2. 0. 0. 0. 0. 3.\n"," 3. 0. 0. 0. 1. 0. 0. 0. 0. 2. 0. 0. 0. 3. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 1. 0. 3. 0. 2. 0. 2.\n"," 2. 0. 2. 1. 2. 2. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 2. 1. 0. 0. 0. 0. 0. 2.\n"," 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 1. 0. 3. 0. 0. 2. 3.\n"," 1. 0. 3. 0. 2. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 3. 0. 3. 1.\n"," 0. 3. 3. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 1. 2. 0. 2. 2. 0. 3. 3. 0. 2. 0. 1. 3. 0. 1. 3. 1. 0. 0. 0.\n"," 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 2. 0. 0. 2. 0. 0. 2. 0.\n"," 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 2. 3. 0. 3. 1. 2. 0. 0. 2. 0.\n"," 0. 0. 0. 0. 0. 1. 0. 0. 2. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 2. 0. 0. 3. 2. 1. 2. 0. 0. 0.\n"," 0. 3. 0. 0. 3. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.\n"," 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 1. 0. 0. 2. 0. 0. 1. 2. 0. 0. 0. 3. 0.\n"," 0. 0. 3. 0. 3. 3. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 3. 0. 0. 1. 0. 2. 0. 0. 0. 0. 0. 0. 0. 1. 3. 0. 2. 3. 0. 2. 0. 1.\n"," 2. 0. 0. 2. 3. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 1. 0. 2. 1. 3.\n"," 0. 3. 0. 0. 0. 0. 0. 2. 2. 0. 1. 3. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 3. 0. 1. 0. 3. 0. 0. 0. 0. 0.\n"," 0. 2. 2. 1. 0. 2. 0. 1. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 3. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 1. 0. 0.\n"," 1. 3. 2. 2. 2. 0. 0. 2. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 3. 1. 0. 2. 0.\n"," 1. 2. 0. 2. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 2. 0. 2. 2. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n"," 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 2. 0.\n"," 0. 3. 0. 0. 0. 0. 0. 3. 2. 0. 0. 0. 2. 0. 0. 3. 0. 0. 0. 0. 0. 2. 3. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 3. 0. 1. 2. 0. 1. 1. 2. 3. 0. 0. 0. 3.\n"," 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 3. 0. 3. 1. 3. 0. 0. 0. 0. 2. 3. 0. 0. 0.\n"," 0. 3. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0.\n"," 2. 0. 3. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 3. 0. 0. 0. 0. 2. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 3. 0. 0. 0.\n"," 0. 0. 3. 0. 0. 3. 2. 0. 0. 1. 0. 0. 1. 0. 3. 0. 3. 2. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 0. 0. 0. 0. 1. 0. 0. 0. 0. 3.\n"," 0. 0. 0. 0. 3. 0. 0. 0. 3. 0. 0. 0. 0. 3. 0. 3. 2. 0. 1. 3. 0. 2. 0. 1.\n"," 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 3. 0. 0. 1. 0. 0. 0. 0. 2. 0. 0. 3. 1. 0. 2. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 2. 2. 0. 1. 0. 1. 0. 0. 3. 0. 0. 1. 1. 0.\n"," 3. 1. 0. 1. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 2. 3. 0. 0. 1. 0. 0. 0. 3. 2. 0. 0. 0. 0. 3. 0. 3. 0. 3.\n"," 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n"," 2. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 3. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 2. 3. 0. 0. 0. 0. 2. 3. 0. 0. 2. 1. 1. 0. 3. 2. 2. 1. 0. 1.\n"," 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 2. 0. 0. 0. 2. 0. 0. 0. 3. 0. 0. 0.\n"," 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 2. 1. 0. 0. 0. 0. 0. 2. 2. 0.\n"," 0. 1. 0. 0. 3. 3. 0. 2. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 3. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 2. 0. 0. 0. 0. 0. 1. 0. 2. 0. 2.\n"," 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 2. 0. 0. 2. 2. 0. 0. 3.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 3. 0. 0. 0. 0. 0.\n"," 0. 2. 0. 0. 2. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 2. 0.\n"," 2. 3. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 2. 0. 3. 0. 0. 0. 3. 0. 0.\n"," 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0.\n"," 3. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 1. 0. 2.\n"," 1. 3. 3. 2. 0. 1. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 2.\n"," 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 1. 2. 0. 2. 3. 0. 1. 0. 0. 0. 0. 0.\n"," 0. 0. 3. 1. 0. 0. 0. 3. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0.\n"," 0. 1. 0. 0. 2. 0. 2. 3. 3. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 1. 0. 2. 0. 0. 3. 0. 0. 2. 0. 3. 3. 2. 1. 1. 0. 0. 0. 0. 3.\n"," 0. 0. 0. 0. 3. 0. 3. 2. 0. 1. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0.\n"," 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 1. 0. 3. 2. 1. 1. 2. 0. 0. 2. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 3. 0. 2. 0. 0. 0. 0. 0. 3. 0. 2. 0. 2. 0. 0. 1. 0. 0. 0. 2. 1. 0. 0. 0.\n"," 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 3. 1. 0. 2. 0. 1. 2. 0. 0. 0. 3. 3. 0. 3. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0.\n"," 3. 0. 0. 0. 1. 0. 0. 3. 0. 0. 0. 2. 0. 2. 1. 1. 2. 0. 2. 0. 0. 0. 0. 0.\n"," 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 3. 2. 0. 1. 0. 0.\n"," 1. 0. 2. 0. 0. 0. 0. 2. 1. 3. 0. 3. 1. 0. 0. 3. 2. 3. 3. 1. 0. 0. 2. 0.\n"," 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 3. 0. 0. 0.\n"," 0. 2. 0. 0. 0. 0. 0. 0. 0. 2. 0. 3. 0. 0. 0. 2. 0. 2. 0. 0. 0. 3. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 2. 1. 2. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.\n"," 0. 0. 0. 1. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 2. 3. 2. 2. 0. 0. 0. 0.\n"," 0. 1. 1. 0. 2. 0. 0. 2. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 3. 0. 2. 1. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 3. 1.\n"," 2. 0. 0. 3. 2. 1. 1. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 2. 3. 3. 0. 0. 0. 0. 0. 0. 0. 2. 1. 3. 0. 0. 0. 0. 0. 1. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0.\n"," 1. 2. 0. 0. 0. 0. 2. 0. 0. 2. 1. 3. 0. 0. 0. 3. 3. 3. 2. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 3. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 2.\n"," 0. 2. 3. 3. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 1. 1. 0. 3. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 2. 0. 0. 1. 2.\n"," 1. 0. 3. 0. 0. 1. 3. 0. 2. 0. 0. 0. 0. 0. 3. 0. 0. 3. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 2. 3. 3. 0. 1.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 1. 3. 0. 0. 0. 0. 0. 0.\n"," 2. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 3. 0. 0. 0. 0.\n"," 1. 3. 0. 0. 0. 3. 3. 2. 2. 2. 0. 0. 2. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n"," 1. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0.\n"," 2. 0. 2. 0. 2. 0. 0. 1. 1. 0. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n"," 0. 0. 0. 1. 0. 0. 0. 3. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 1. 0. 2. 0. 2.\n"," 0. 0. 2. 0. 1. 3. 3. 1. 3. 0. 3. 0. 0. 2. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 1. 3. 0. 0. 3. 0. 2. 0. 2. 0. 0. 2. 0. 0. 0. 2. 0. 1.\n"," 2. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0.\n"," 0. 2. 0. 2. 2. 0. 3. 0. 0. 2. 2. 0. 1. 0. 0. 0. 1. 2. 3. 1. 0. 0. 0. 1.\n"," 2. 1. 0. 0. 0. 1. 0. 0. 0. 0. 2. 0. 2. 0. 0. 0. 2. 0. 0. 0. 0. 1. 0. 0.\n"," 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 3. 0. 2. 2. 3. 0. 0. 0. 0. 0. 0. 2.\n"," 2. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 3. 0. 0. 2. 0. 3. 2.\n"," 1. 3. 0. 0. 0. 0. 0. 2. 3. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 2. 0.\n"," 0. 0. 0. 1. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 1.\n"," 0. 0. 2. 0. 3. 2. 0. 0. 0. 0. 0. 0. 2. 1. 2. 1. 1. 0. 0. 3. 0. 0. 0. 0.\n"," 0. 2. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0.\n"," 2. 0. 0. 3. 0. 3. 0. 0. 3. 2. 0. 0. 0. 3. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0.\n"," 3. 0. 3. 0. 0. 0. 2. 0. 0. 0. 0. 0. 3. 1. 2. 3. 0. 3. 0. 0. 0. 0. 3. 0.\n"," 0. 0. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 3. 0. 1. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 3. 0. 0. 0. 2. 0. 3. 0. 0. 0. 2. 1. 0. 0.\n"," 3. 0. 2. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 2. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 2. 0. 0. 1. 0. 0. 0. 2. 0. 1. 2. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 2. 0. 2. 2. 0. 0. 3. 1. 2. 2. 2. 3. 2. 1. 2. 3. 1. 0.\n"," 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 3. 0. 0. 0. 0. 3. 0. 2. 0. 3. 0. 0. 3. 3. 3. 0. 3. 2. 1. 1. 2. 0.\n"," 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.\n"," 0. 0. 1. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 1. 0. 0. 2. 0. 2. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 1. 0. 0. 0. 0. 2. 0. 3. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 3. 0. 2. 0.\n"," 0. 0. 3. 1. 2. 0. 2. 1. 0. 0. 2. 3. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0.\n"," 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 2. 3. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1.\n"," 0. 1. 2. 2. 2. 0. 0. 0. 2. 0. 3. 0. 1. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0.\n"," 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 2. 0. 1. 0. 0. 0. 1. 2. 0. 0. 0.\n"," 2. 0. 1. 0. 0. 3. 0. 1. 1. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 3. 0.\n"," 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 1. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 2. 3. 0. 0. 0. 0. 3. 3. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 1. 2. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 3. 0. 0. 0. 2. 0. 0.\n"," 0. 0. 0. 0. 0. 2. 1. 0. 1. 2. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 2. 0. 0. 0.\n"," 3. 0. 3. 0. 0. 0. 0. 0. 2. 0. 0. 0. 2. 0. 1. 0. 0. 2. 1. 0. 1. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 3. 0. 0. 0. 2. 0. 3. 3. 0. 0. 0. 3. 1. 0. 2. 2. 2. 2. 0. 2. 2. 0. 0.\n"," 2. 2. 0. 1. 0. 0. 3. 3. 0. 0. 0. 0. 0. 0. 0. 0. 3. 1. 1. 0. 0. 0. 0. 0.\n"," 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 2. 3. 0. 2. 0. 0.\n"," 0. 0. 0. 3. 2. 0. 3. 2. 3. 0. 0. 0. 0. 0. 2. 3. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 2. 3. 1. 0. 0. 3. 3. 0. 0.\n"," 3. 0. 2. 0. 2. 0. 0. 0. 3. 0. 3. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 3. 3. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 2. 1. 2. 1. 0. 0. 0. 0. 0. 0. 3. 2.\n"," 1. 1. 2. 0. 3. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 2. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 3. 1. 0. 0. 0. 0. 0. 2. 1. 0. 0.\n"," 0. 0. 0. 3. 2. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 2. 0.\n"," 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 3. 2. 0. 0. 3. 0. 3.\n"," 0. 0. 0. 1. 0. 0. 2. 0. 0. 0. 0. 2. 0. 0. 2. 0. 0. 0. 0. 0. 3. 0. 0. 0.\n"," 0. 0. 0. 0. 2. 0. 0. 3. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0.\n"," 0. 2. 2. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 1. 0. 0.\n"," 0. 0. 0. 0. 2. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0.\n"," 3. 0. 2. 0. 0. 0. 2. 2. 1. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0. 3. 1. 0.\n"," 2. 1. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 3. 3. 2. 3. 0. 0. 0. 0. 2. 0. 1.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 3. 1. 2. 0. 0. 1. 2. 2. 0. 0. 1.\n"," 0. 2. 0. 3. 3. 3. 3. 0. 3. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 3. 0. 2. 2. 0. 0. 3. 0. 0. 0. 0. 1. 3. 0. 0. 0. 0. 2. 0. 0. 0. 2. 0. 0.\n"," 0. 0. 0. 2. 1. 0. 2. 0. 0. 0. 0. 0. 0. 0. 3. 2. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 3. 2. 0. 0. 0. 0. 3. 0. 0. 0.\n"," 1. 1. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0.\n"," 3. 3. 0. 1. 0. 0. 0. 2. 0. 0. 3. 2. 0. 0. 0. 1. 3. 1. 1. 1. 0. 3. 2. 2.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0.\n"," 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 2. 0. 0.\n"," 0. 1. 3. 0. 0. 0. 0. 0. 0. 1. 0. 2. 0. 0. 0. 0. 2. 2. 0. 0. 2. 2. 3. 3.\n"," 0. 1. 0. 3. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 3. 3. 0. 0. 0. 0. 1. 3. 0. 0. 0.\n"," 0. 1. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 2. 2. 2. 0. 0. 2. 2. 2. 0. 1. 0.\n"," 2. 2. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 3. 3. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.\n"," 0. 2. 0. 0. 0. 0. 0. 0. 0. 3. 1. 0. 2. 1. 0. 2. 2. 2. 3. 0. 0. 3. 0. 0.\n"," 0. 0. 0. 3. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 3. 0. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 3. 3. 0.\n"," 0. 2. 0. 1. 1. 0. 1. 2. 0. 0. 0. 0. 0. 0. 1. 2. 0. 0. 0. 0. 1. 0. 0. 0.\n"," 0. 0. 0. 0. 3. 0. 0. 0. 0. 1. 0. 2. 2. 2. 0. 0. 2. 0. 0. 2. 1. 0. 2. 1.\n"," 2. 1. 0. 2. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 3. 2. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 2. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0.\n"," 2. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 3. 3. 0. 0. 2. 0. 2. 1. 0. 0. 1. 0. 2. 0. 1. 3. 3. 3. 2. 2. 2. 2. 0.\n"," 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n"," 0. 0. 0. 0. 0. 0. 3. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 2. 0. 2. 0. 0. 1.\n"," 0. 3. 2. 2. 0. 0. 0. 0. 2. 1. 0. 0. 0. 0. 0. 0. 2. 0. 1. 0. 0. 0. 0. 2.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 2. 0. 1. 2. 2. 1. 0. 0. 0. 1. 2.\n"," 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 2.\n"," 0. 0. 3. 0. 1. 0. 3. 0. 0. 3. 0. 1. 2. 2. 3. 2. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 2. 0. 1.\n"," 0. 0. 0. 0. 2. 1. 0. 2. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 0. 2. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 3. 0. 1. 0. 0. 0. 1. 2. 2. 0. 2. 0. 2. 1. 2. 3. 1. 2. 0. 1. 0. 2. 0. 0.\n"," 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 3. 3. 0. 1. 0. 0. 0. 0. 0. 1. 0. 3. 0. 3. 0. 2. 0. 0. 0.\n"," 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 2. 0. 2. 3. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 1. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 1. 0. 0. 3. 0.\n"," 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 1. 0. 2. 3. 0. 1. 3. 0. 0. 0.\n"," 1. 2. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 1. 0. 0. 0. 0. 2. 0.\n"," 0. 3. 0. 0. 0. 1. 0. 2. 0. 0. 0. 0. 2. 1. 1. 0. 0. 0. 0. 0. 0. 0. 3. 0.\n"," 0. 0. 0. 0. 0. 3. 3. 0. 0. 0. 0. 0. 0. 3. 0. 2. 0. 2. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 1. 2. 2. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 3.\n"," 0. 0. 3. 0. 3. 2. 0. 0. 0. 3. 0. 1. 3. 0. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 2. 0. 1. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 1. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.\n"," 3. 3. 1. 2. 2. 0. 0. 3. 0. 0. 3. 0. 3. 1. 3. 0. 0. 2. 2. 2. 0. 0. 0. 0.\n"," 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 1. 0. 0. 0.\n"," 0. 1. 0. 0. 0. 0. 0. 2. 3. 2. 0. 0. 3. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 2. 0. 0. 0.\n"," 1. 3. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 3. 0. 0. 0. 0.\n"," 0. 3. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 2. 3. 0. 3. 0. 0. 0. 3. 0. 1. 0. 0. 0. 0.\n"," 2. 2. 0. 0. 0. 1. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 1. 3. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 2. 0. 3. 0. 0. 0. 3. 0. 0. 0.\n"," 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 1. 2. 2. 0. 0. 0. 3. 0. 0. 0. 0. 3. 0. 0. 2. 0. 2. 0. 0. 1. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 3. 0. 1. 0. 3. 0. 0. 3. 0. 3. 3. 0. 2. 1. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 3. 2.\n"," 0. 0. 0. 0. 0. 0. 1. 0. 2. 1. 0. 2. 0. 0. 1. 3. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 1. 0. 0. 2. 3. 0. 0.\n"," 2. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n"," 0. 0. 0. 2. 0. 0. 3. 0. 3. 1. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 3. 3. 2. 0. 3. 1. 0. 0. 2. 0. 3. 1. 3. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 1. 0. 0. 0. 2. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 1. 3. 3. 3. 0. 2. 3. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 3. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0.\n"," 0. 0. 0. 1. 3. 2. 0. 1. 0. 3. 0. 0. 1. 2. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 3. 0. 0. 0. 3. 0. 0. 0. 0. 0. 1.\n"," 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 3. 2. 3. 0. 2. 0. 2. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 3. 0.\n"," 0. 0. 0. 0. 1. 0. 0. 3. 0. 0. 0. 3. 2. 3. 0. 2. 0. 0. 2. 0. 0. 3. 0. 3.\n"," 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n"," 0. 3. 0. 0. 3. 0. 0. 0. 0. 2. 0. 3. 2. 0. 2. 3. 3. 3. 3. 0. 0. 0. 2. 0.\n"," 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 3.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 2. 0. 3. 1. 0. 0. 0. 1. 2.\n"," 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 3. 1. 1. 3. 3. 2. 1. 2. 2. 3. 2. 1. 1.\n"," 0. 0. 2. 3. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 1. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 3. 3. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 3. 0. 0. 1. 0. 2. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 3. 1. 2. 2. 1. 0. 3. 0. 0. 0. 2. 3.\n"," 2. 2. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 3. 0. 3.\n"," 0. 0. 3. 1. 0. 0. 3. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 3. 3. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0.\n"," 0. 2. 0. 0. 0. 0. 0. 1. 0. 2. 3. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 0. 3. 1. 0. 3. 3. 0. 0. 1. 0.\n"," 2. 0. 0. 2. 0. 0. 0. 2. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 1. 1. 3. 0. 0. 0. 0. 3. 0. 1. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 2. 0. 3. 2. 2. 1. 0. 0.\n"," 0. 0. 0. 0. 0. 3. 0. 1. 2. 0. 2. 0. 2. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 3. 3. 2. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 3. 1. 0. 0. 0.\n"," 1. 0. 0. 0. 0. 0. 0. 0. 3. 3. 2. 0. 0. 2. 0. 0. 1. 0. 0. 3. 2. 1. 0. 1.\n"," 0. 0. 3. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 3.\n"," 0. 3. 0. 0. 0. 0. 3. 0. 0. 1. 0. 0. 0. 0. 2. 0. 0. 1. 0. 0. 0. 3. 0. 0.\n"," 3. 0. 2. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 3. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 3. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 3.\n"," 0. 0. 0. 0. 2. 2. 0. 2. 3. 0. 0. 3. 2. 1. 0. 1. 2. 0. 3. 3. 2. 0. 0. 0.\n"," 1. 0. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 2. 0. 2. 2. 0.\n"," 1. 3. 3. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 3. 0. 2. 2. 0. 0. 3. 0. 0. 3. 3. 2. 3. 0. 2. 0. 3.\n"," 1. 0. 2. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 2. 3. 0. 1. 0. 0.\n"," 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 3. 0.\n"," 2. 0. 2. 0. 0. 0. 0. 0. 3. 0. 3. 0. 2. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 3. 0. 0. 0. 0. 2. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 3. 3. 0. 0. 0. 1.\n"," 0. 0. 0. 0. 2. 0. 1. 0. 3. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 2. 1. 1.\n"," 2. 0. 3. 3. 0. 2. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n"," 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 3. 1. 3. 1. 0. 3. 3. 0. 0. 0. 0. 0. 0. 1.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 3.\n"," 0. 2. 1. 0. 0. 2. 2. 0. 0. 0. 3. 2. 0. 2. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 3. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 3.\n"," 2. 0. 3. 0. 2. 0. 1. 0. 0. 1. 0. 2. 0. 0. 0. 2. 2. 0. 1. 0. 0. 0. 0. 0.\n"," 0. 2. 0. 0. 2. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 3. 0. 2. 2. 0. 3. 3. 1. 0. 0. 0. 0. 1. 2. 0. 2. 0. 2. 0. 0. 0. 2. 0. 0.\n"," 0. 0. 0. 1. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 2. 0. 1. 3. 2. 0. 2. 3. 0. 0. 1. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0.\n"," 2. 3. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 2. 0. 0. 0. 0. 1. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 2. 0. 2. 2. 0. 0. 1. 3.\n"," 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 2. 0. 0. 0. 1. 0. 0. 3. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0. 0. 3. 0. 0. 2. 1. 0. 3. 0. 0. 0.\n"," 2. 3. 2. 2. 0. 0. 2. 0.]\n"]}],"source":["import sys\n","np.set_printoptions(threshold=sys.maxsize)\n","\n","#print(Xt_norm.shape)\n","pred = predictOneVsAll(all_theta, Xt_norm)\n","\n","print('Precision del conjuto de entrenamiento: {:.2f}%'.format(np.mean(pred == ytest) * 100))\n","#XPrueba = Xtest_norm[:, :].copy()\n","#print(XPrueba.shape)\n","#print(np.ones((1)))\n","#print(XPrueba)\n","#p = np.zeros(1)\n","#XPrueba = np.concatenate([np.ones((8000, 1)), XPrueba], axis=1)\n","#print(XPrueba.shape)\n","#p = np.argmax(sigmoid(XPrueba.dot(all_theta.T)), axis = 1)\n","#print(pred.shape)\n","print(pred)\n","\n","# displayData(X[1002:1003, :])\n","print(ytest[:])\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPUICNt3JO5aXIUlKxeV4+a","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}
